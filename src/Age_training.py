# -*- coding: utf-8 -*-
"""rawAge.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14ulVWUTjLzrIYyw_6ISysFySkgelVnY4
"""

from google.colab import drive
drive.mount("/content/gdrive")

from google.colab import drive
import numpy as np
import scipy.io
import pandas as pd
from datetime import datetime, timedelta
import os
import tensorflow as tf
import keras
from keras.preprocessing import image
from keras.callbacks import ModelCheckpoint,EarlyStopping
from keras.layers import Dense, Activation, Dropout, Flatten, Input, \
Convolution2D, ZeroPadding2D, MaxPooling2D
from keras.layers import Conv2D, AveragePooling2D
from keras.models import Model, Sequential
from sklearn.model_selection import train_test_split
from keras import metrics
from keras.models import model_from_json
import matplotlib.pyplot as plt
from glob import glob
import math
import shutil
import re
import cv2
from PIL import Image
from keras.preprocessing.image import load_img, save_img, img_to_array, ImageDataGenerator
from keras.applications.imagenet_utils import preprocess_input
from os import listdir

!unzip /content/gdrive/'My Drive'/'final crop faces.zip'



# os.rename("cleaned", "Main")

# !mv /content/20 Main

"""### Pre-Trained weights Download"""



# download dataset from drive
!gdown --id 1Yc4JhKcwP3j_9MCv_U5eb_f_L1mHeqmJ

# vgg face model
!gdown --id 1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo

# age weights
!gdown --id 1YCox_4kJ-BYeXq27uUbasu--yz28zUMV

"""# VGG"""

#os.rename("cleaned", "Main")



# !rm Main/41/41.0_imdb_100__01_nm0001001_rm2306718464_1940-3-26_1981.jpg

IMAGE_SIZE = [224,224]
path='/content/final crop faces'
# preprocessing_function is applied on each image but only after re-sizing & augmentation (resize => augment => pre-process)
# Each of the keras.application.resnet* preprocess_input MOSTLY mean BATCH NORMALIZATION (applied on each batch) stabilize the inputs to nonlinear activation functions
# Batch Normalization helps in faster convergence
data_generator = ImageDataGenerator(rescale = 1./255,validation_split= 0.2)

training_set = data_generator.flow_from_directory(path, target_size=IMAGE_SIZE, class_mode='categorical',
                                          subset= 'training', shuffle = True, batch_size=256)
test_set = data_generator.flow_from_directory(path, target_size=IMAGE_SIZE, class_mode='categorical',
                                      subset= 'validation', shuffle=True, batch_size=256)

nb_classes = training_set.num_classes

# nb_classes

def loadVggFaceModel():
	model = Sequential()
	model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))
	model.add(Convolution2D(64, (3, 3), activation='relu'))
	model.add(ZeroPadding2D((1,1)))
	model.add(Convolution2D(64, (3, 3), activation='relu'))
	model.add(MaxPooling2D((2,2), strides=(2,2)))

	model.add(ZeroPadding2D((1,1)))
	model.add(Convolution2D(128, (3, 3), activation='relu'))
	model.add(ZeroPadding2D((1,1)))
	model.add(Convolution2D(128, (3, 3), activation='relu'))
	model.add(MaxPooling2D((2,2), strides=(2,2)))

	model.add(ZeroPadding2D((1,1)))
	model.add(Convolution2D(256, (3, 3), activation='relu'))
	model.add(ZeroPadding2D((1,1)))
	model.add(Convolution2D(256, (3, 3), activation='relu'))
	model.add(ZeroPadding2D((1,1)))
	model.add(Convolution2D(256, (3, 3), activation='relu'))
	model.add(MaxPooling2D((2,2), strides=(2,2)))

	model.add(ZeroPadding2D((1,1)))
	model.add(Convolution2D(512, (3, 3), activation='relu'))
	model.add(ZeroPadding2D((1,1)))
	model.add(Convolution2D(512, (3, 3), activation='relu'))
	model.add(ZeroPadding2D((1,1)))
	model.add(Convolution2D(512, (3, 3), activation='relu'))
	model.add(MaxPooling2D((2,2), strides=(2,2)))

	model.add(ZeroPadding2D((1,1)))
	model.add(Convolution2D(512, (3, 3), activation='relu'))
	model.add(ZeroPadding2D((1,1)))
	model.add(Convolution2D(512, (3, 3), activation='relu'))
	model.add(ZeroPadding2D((1,1)))
	model.add(Convolution2D(512, (3, 3), activation='relu'))
	model.add(MaxPooling2D((2,2), strides=(2,2)))

	model.add(Convolution2D(4096, (7, 7), activation='relu'))
	model.add(Dropout(0.5))
	model.add(Convolution2D(4096, (1, 1), activation='relu'))
	model.add(Dropout(0.5))
	model.add(Convolution2D(2622, (1, 1)))
	model.add(Flatten())
	model.add(Activation('softmax'))
	
	return model

model = loadVggFaceModel()





model.load_weights('vgg_face_weights.h5')

for layer in model.layers[:-7]:
    layer.trainable = False
 
base_model_output = Sequential()
base_model_output = Convolution2D(nb_classes, (1, 1), name='predictions')(model.layers[-4].output)
base_model_output = Dropout(0.5)(base_model_output)
base_model_output = Flatten()(base_model_output)
base_model_output = Dense(128, kernel_regularizer= keras.regularizers.l2(l=0.005))(base_model_output)
base_model_output = Activation('relu')(base_model_output)
base_model_output = Dense(nb_classes)(base_model_output)
base_model_output = Activation('softmax')(base_model_output)
base_model_output = Dropout(0.3)(base_model_output)
 
age_model = Model(inputs=model.input, outputs=base_model_output)

age_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])



checkpointer = ModelCheckpoint(
    filepath='/content/gdrive/My Drive/age_weights.hdf5'
    , monitor = "val_loss"
    , verbose=1
    , save_weights_only=True
    , mode = 'auto'
)

age_model.fit_generator(training_set, steps_per_epoch=int(len(training_set)/4),
                        epochs = 200, validation_data=test_set, 
                        validation_steps = int(len(test_set)), verbose=1,
                        callbacks = [checkpointer])





# !ls Main/20

# !rm -r Main/110

# !tar -czvf Main.tar.gz Main

# test_set